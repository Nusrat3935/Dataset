# -*- coding: utf-8 -*-
"""nusrat project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wd4N2NCXMQZoOf8zCBE07c4UJnNv8wUu

# Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Load Dataset"""

df=pd.read_csv(r"https://raw.githubusercontent.com/Nusrat3935/Dataset/refs/heads/main/data%20-%20Copy.csv")

"""# EDA (Exploratory Data Analysis)

### a. Understanding the Dataset

- Head of the dataset
- Shape of the data set
- Types of columns
- Information about data set
- Summary of the data set
"""

df.head()

"""### b. Cleaning the Dataset

- Dropping duplicate values
- Checking NULL values
- Checking for 0 value and replacing it
"""

df = df.drop_duplicates()

df.isnull().sum()

"""### Checking for specified value occurance in feature

### Fill the zero
"""

for col in df.columns:
    if df[col].dtype != 'object' and col != 'diagnosis':
        df[col] = df[col].replace(0, np.NaN)
        mean_val = df[col].mean(skipna=True)
        df[col] = df[col].replace(np.NaN, mean_val)

y=(df==0).sum()
y

"""### Drop unneccessary columns"""

df=df.drop(["id"],axis=1)
df

df=df.dropna(axis=1)
df

"""### Convert object type to int type(diagnosis)"""

sns.countplot(x="diagnosis",data=df)

data=df

from sklearn.preprocessing import LabelEncoder

lb=LabelEncoder()

data['diagnosis']=lb.fit_transform(data["diagnosis"])

data

data.info()

"""# Data Visualization"""

data.hist(bins=31,figsize=(20,20))
plt.show

plt.figure(figsize=(20,24))
sns.set_style(style='whitegrid')

plt.subplot(6,5,1)
sns.boxplot(x='radius_mean',data=data)
plt.subplot(6,5,2)
sns.boxplot(x='texture_mean',data=data)
plt.subplot(6,5,3)
sns.boxplot(x='perimeter_mean',data=data)
plt.subplot(6,5,4)
sns.boxplot(x='area_mean',data=data)
plt.subplot(6,5,5)
sns.boxplot(x='smoothness_mean',data=data)

plt.subplot(6,5,6)
sns.boxplot(x='compactness_mean',data=data)
plt.subplot(6,5,7)
sns.boxplot(x='concavity_mean',data=data)
plt.subplot(6,5,8)
sns.boxplot(x='concave points_mean',data=data)
plt.subplot(6,5,9)
sns.boxplot(x='symmetry_mean',data=data)
plt.subplot(6,5,10)
sns.boxplot(x='fractal_dimension_mean',data=data)

plt.subplot(6,5,11)
sns.boxplot(x='radius_se',data=data)
plt.subplot(6,5,12)
sns.boxplot(x='texture_se',data=data)
plt.subplot(6,5,13)
sns.boxplot(x='perimeter_se',data=data)
plt.subplot(6,5,14)
sns.boxplot(x='area_se',data=data)
plt.subplot(6,5,15)
sns.boxplot(x='smoothness_se',data=data)

plt.subplot(6,5,16)
sns.boxplot(x='compactness_se',data=data)
plt.subplot(6,5,17)
sns.boxplot(x='concavity_se',data=data)
plt.subplot(6,5,18)
sns.boxplot(x='concave points_se',data=data)
plt.subplot(6,5,19)
sns.boxplot(x='symmetry_se',data=data)
plt.subplot(6,5,20)
sns.boxplot(x='fractal_dimension_se',data=data)

plt.subplot(6,5,21)
sns.boxplot(x='radius_worst',data=data)
plt.subplot(6,5,22)
sns.boxplot(x='texture_worst',data=data)
plt.subplot(6,5,23)
sns.boxplot(x='perimeter_worst',data=data)
plt.subplot(6,5,24)
sns.boxplot(x='area_worst',data=data)
plt.subplot(6,5,25)
sns.boxplot(x='smoothness_worst',data=data)

plt.subplot(6,5,26)
sns.boxplot(x='compactness_worst',data=data)
plt.subplot(6,5,27)
sns.boxplot(x='concavity_worst',data=data)
plt.subplot(6,5,28)
sns.boxplot(x='concave points_worst',data=data)
plt.subplot(6,5,29)
sns.boxplot(x='symmetry_worst',data=data)
plt.subplot(6,5,30)
sns.boxplot(x='fractal_dimension_worst',data=data)

plt.show()

from pandas.plotting import scatter_matrix
scatter_matrix(data,figsize=(50,50),color='red')

"""# Handling Outliers

### Outliers removal
"""

from sklearn.preprocessing import QuantileTransformer
x=data.drop(['diagnosis'],axis=1)
quantile  = QuantileTransformer(n_quantiles=569)
w=quantile.fit_transform(x)
data_new=pd.DataFrame(w,columns=x.columns)
data_new['diagnosis'] = data['diagnosis'].values

data_new.head()

plt.figure(figsize=(20,24))
sns.set_style(style='whitegrid')

plt.subplot(6,5,1)
sns.boxplot(x='radius_mean',data=data_new)
plt.subplot(6,5,2)
sns.boxplot(x='texture_mean',data=data_new)
plt.subplot(6,5,3)
sns.boxplot(x='perimeter_mean',data=data_new)
plt.subplot(6,5,4)
sns.boxplot(x='area_mean',data=data_new)
plt.subplot(6,5,5)
sns.boxplot(x='smoothness_mean',data=data_new)

plt.subplot(6,5,6)
sns.boxplot(x='compactness_mean',data=data_new)
plt.subplot(6,5,7)
sns.boxplot(x='concavity_mean',data=data_new)
plt.subplot(6,5,8)
sns.boxplot(x='concave points_mean',data=data_new)
plt.subplot(6,5,9)
sns.boxplot(x='symmetry_mean',data=data_new)
plt.subplot(6,5,10)
sns.boxplot(x='fractal_dimension_mean',data=data_new)

plt.subplot(6,5,11)
sns.boxplot(x='radius_se',data=data_new)
plt.subplot(6,5,12)
sns.boxplot(x='texture_se',data=data_new)
plt.subplot(6,5,13)
sns.boxplot(x='perimeter_se',data=data_new)
plt.subplot(6,5,14)
sns.boxplot(x='area_se',data=data_new)
plt.subplot(6,5,15)
sns.boxplot(x='smoothness_se',data=data_new)

plt.subplot(6,5,16)
sns.boxplot(x='compactness_se',data=data_new)
plt.subplot(6,5,17)
sns.boxplot(x='concavity_se',data=data_new)
plt.subplot(6,5,18)
sns.boxplot(x='concave points_se',data=data_new)
plt.subplot(6,5,19)
sns.boxplot(x='symmetry_se',data=data_new)
plt.subplot(6,5,20)
sns.boxplot(x='fractal_dimension_se',data=data_new)

plt.subplot(6,5,21)
sns.boxplot(x='radius_worst',data=data_new)
plt.subplot(6,5,22)
sns.boxplot(x='texture_worst',data=data_new)
plt.subplot(6,5,23)
sns.boxplot(x='perimeter_worst',data=data_new)
plt.subplot(6,5,24)
sns.boxplot(x='area_worst',data=data_new)
plt.subplot(6,5,25)
sns.boxplot(x='smoothness_worst',data=data_new)

plt.subplot(6,5,26)
sns.boxplot(x='compactness_worst',data=data_new)
plt.subplot(6,5,27)
sns.boxplot(x='concavity_worst',data=data_new)
plt.subplot(6,5,28)
sns.boxplot(x='concave points_worst',data=data_new)
plt.subplot(6,5,29)
sns.boxplot(x='symmetry_worst',data=data_new)
plt.subplot(6,5,30)
sns.boxplot(x='fractal_dimension_worst',data=data_new)

plt.show()

sns.pairplot(data_new,hue="diagnosis")

"""#  Split Dataset for dependent and independent Features"""

X=data_new.drop(['diagnosis'],axis=1)
y=data_new['diagnosis']

from imblearn.over_sampling import SMOTE

from sklearn.preprocessing import StandardScaler

"""# Train Test Split"""

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

from collections import Counter
print("Resampled dataset class distribution:", Counter(y_train_resampled))

sns.countplot(x=y_train_resampled)

from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

from sklearn.neural_network import MLPClassifier


from sklearn.model_selection import cross_validate, KFold


from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

import warnings
warnings.filterwarnings('ignore')

from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier

models = {
    "Support Vector Machine": SVC(
        C=10, degree=3, gamma= 0.001, kernel='rbf'
    ),

    "KNN": KNeighborsClassifier(
        n_neighbors=30,
        weights='uniform',
        algorithm='auto',
        p=1
    ),

    "Naive Bayes": GaussianNB(
        var_smoothing=1e-9
    ),

    "Neural Network": MLPClassifier(
        hidden_layer_sizes=(100, 50),
        activation='relu',
        solver='adam',
        max_iter=1000,
        alpha=0.0001,
        learning_rate='adaptive',
        learning_rate_init=0.001,
        random_state=0
    )
}

k_values = [35,36,37,38,39,40]

results = {model_name: {"accuracy": [], "precision": [], "recall": [], "f1_score": [], "roc_auc": []}
           for model_name in models}


for k in k_values:

    kf = KFold(n_splits=k, shuffle=True, random_state=0)

    for model_name, model in models.items():

        scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc']
        scores = cross_validate(model, X_train_resampled, y_train_resampled, cv=kf, scoring=scoring)


        results[model_name]["accuracy"].append(np.mean(scores['test_accuracy']))
        results[model_name]["precision"].append(np.mean(scores['test_precision_macro']))
        results[model_name]["recall"].append(np.mean(scores['test_recall_macro']))
        results[model_name]["f1_score"].append(np.mean(scores['test_f1_macro']))
        results[model_name]["roc_auc"].append(np.mean(scores['test_roc_auc']))

metrics = ["accuracy", "precision", "recall", "f1_score", "roc_auc"]

plt.figure(figsize=(15, 10))


for i, metric in enumerate(metrics, 1):
    plt.subplot(2, 3, i)

    for model in models:
        plt.plot(k_values, results[model][metric], marker='o', label=model)

    plt.title(f"{metric.capitalize()} Comparison")
    plt.xlabel("k-Fold")
    plt.ylabel(metric.capitalize())
    plt.legend()
    plt.grid(True)

plt.tight_layout()
plt.show()

table_data = []
for model_name, scores in results.items():
    row = {
        "Model": model_name,
        "Accuracy": ", ".join(["{:.4f}".format(score) for score in scores["accuracy"]]),
        "Precision": ", ".join(["{:.4f}".format(score) for score in scores["precision"]]),
        "Recall": ", ".join(["{:.4f}".format(score) for score in scores["recall"]]),
        "F1-Score": ", ".join(["{:.4f}".format(score) for score in scores["f1_score"]]),
        "AUC-ROC": ", ".join(["{:.4f}".format(score) for score in scores["roc_auc"]]),
    }
    table_data.append(row)

modelcomparison = pd.DataFrame(table_data)

modelcomparison

summary_data = []

for model_name, scores in results.items():
    for i, k in enumerate(k_values):
        summary_data.append([
            model_name if i == 0 else "",
            k,
            f"{scores['accuracy'][i]:.4f}",
            f"{scores['precision'][i]:.4f}",
            f"{scores['recall'][i]:.4f}",
            f"{scores['f1_score'][i]:.4f}",
            f"{scores['roc_auc'][i]:.4f}",
        ])


columns = ["Model", "k", "Accuracy", "Precision", "Recall", "F1-Score", "AUC-ROC"]
summary_df = pd.DataFrame(summary_data, columns=columns)


summary_df.to_string(index=False)
summary_df